# """
# âœ… verify_alpha158_indicators.py
# -------------------------------------------------------
# é‡ç¾ Qlib Alpha158 æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™ä¸¦é©—è­‰çµæžœä¸€è‡´æ€§
# ä½¿ç”¨æ–¹æ³•ï¼š
#     python verify_alpha158_indicators.py --symbol 1101
# """
import ast
# import argparse
# from pathlib import Path
# import numpy as np
# import pandas as pd
# from qlib.contrib.data.handler import Alpha158
# import qlib
# import re

# # =======================================================
# # 1ï¸âƒ£ åˆå§‹åŒ– Qlib
# # =======================================================
# qlib.init(provider_uri="./data/qlib_data/day1", region="cn", num_workers=8)
# print("âœ… Qlib Initialized")

# # =======================================================
# # 2ï¸âƒ£ é‹ç®—å‡½æ•¸è¡¨ï¼ˆå®Œæ•´æ“´å……ï¼‰
# # =======================================================
# OPS = {
#     # === åŸºæœ¬æ•¸å­¸ ===
#     "Greater": np.maximum,
#     "Less": np.minimum,
#     "Abs": np.abs,
#     # "Log": np.log1p,
#     "Log": np.log,
#     "SignedPower": lambda x, y: np.sign(x) * np.abs(x) ** y,

#     # === æ»¾å‹•çµ±è¨ˆ ===
#     "Mean": lambda x, n: x.rolling(int(n), min_periods=1).mean(),
#     "Std": lambda x, n: x.rolling(int(n), min_periods=1).std(),
#     "Var": lambda x, n: x.rolling(int(n), min_periods=1).var(),
#     "Max": lambda x, n: x.rolling(int(n), min_periods=1).max(),
#     "Min": lambda x, n: x.rolling(int(n), min_periods=1).min(),
#     "Sum": lambda x, n: x.rolling(int(n), min_periods=1).sum(),
#     "Delay": lambda x, n: x.shift(int(n)),
#     "Ref": lambda x, n: x.shift(int(n)),

#     # === Rank / Quantile ===
#     "Rank": lambda x, n=None: (
#         x.rolling(int(n), min_periods=1).apply(lambda s: s.rank(pct=True).iloc[-1])
#         if n else x.rank(pct=True)
#     ),
#     "Quantile": lambda x, n, q: x.rolling(int(n), min_periods=1).quantile(float(q)),

#     # === Regression èˆ‡çµ±è¨ˆ ===
#     "Slope": lambda x, n: x.rolling(int(n), min_periods=3).apply(
#         lambda s: np.polyfit(np.arange(len(s)), s, 1)[0] if len(s.dropna()) > 2 else np.nan
#     ),
#     "Rsquare": lambda x, n: x.rolling(int(n), min_periods=3).apply(
#         lambda s: (np.corrcoef(np.arange(len(s)), s)[0, 1] ** 2)
#         if s.std() > 0 else np.nan
#     ),
#     "Resi": lambda x, n: x.rolling(int(n), min_periods=3).apply(
#         lambda s: s.iloc[-1] - np.poly1d(np.polyfit(np.arange(len(s)), s, 1))(len(s) - 1)
#         if len(s.dropna()) > 2 else np.nan
#     ),
#     "Beta": lambda x, y, n: x.rolling(int(n), min_periods=1).cov(y)
#         / (y.rolling(int(n), min_periods=1).var() + 1e-12),

#     # === IdxMax / IdxMin ===
#     "IdxMax": lambda x, n: x.rolling(int(n), min_periods=1).apply(
#         lambda s: np.argmax(s) + 1, raw=True
#     ),
#     "IdxMin": lambda x, n: x.rolling(int(n), min_periods=1).apply(
#         lambda s: np.argmin(s) + 1, raw=True
#     ),
#     "IMXD": lambda x, n: OPS["IdxMax"](x, n) - OPS["IdxMin"](x, n),

#     # === CNTP / CNTN / CNTD ===
#     "CNTP": lambda x, n: x.diff().fillna(0).gt(0).rolling(int(n), min_periods=1).sum(),
#     "CNTN": lambda x, n: x.diff().fillna(0).lt(0).rolling(int(n), min_periods=1).sum(),
#     "CNTD": lambda x, n: x.diff().fillna(0).eq(0).rolling(int(n), min_periods=1).sum(),

#     # === Volume Weighted Mean / Std ===
#     "VMA": lambda v, n: OPS["Mean"](v, n) / (v + 1e-12),
#     "VSTD": lambda v, n: OPS["Std"](v, n) / (v + 1e-12),

#     # === Corr / Cov ===
#     # "Corr": lambda x, y, n: x.rolling(int(n), min_periods=3).corr(y),
#     "Cov": lambda x, y, n: x.rolling(int(n), min_periods=3).cov(y),

#     # === Corr / Cord ===
#     "Corr": lambda x, y, n: x.rolling(int(n), min_periods=3).corr(y),
#     "CORD": lambda x, y, n: (
#         (x / OPS["Ref"](x, 1))
#         .rolling(int(n), min_periods=3)
#         .corr(np.log(y / OPS["Ref"](y, 1) + 1))
#     )
# }

# # =======================================================
# # 3ï¸âƒ£ Qlib DSL â†’ Python å¯åŸ·è¡Œè½‰æ›
# # =======================================================
# def qlib_expr_to_python(expr: str) -> str:
#     expr = expr.strip()
#     expr = re.sub(r"\$(\w+)", r'env["\1"]', expr)
#     expr = re.sub(r"\b([A-Z][A-Za-z0-9_]*)\s*\(", r'OPS["\1"](', expr)
#     expr = re.sub(r"\s+", " ", expr)
#     return expr

# # =======================================================
# # 4ï¸âƒ£ AST å®‰å…¨è§£æž
# # =======================================================
# class SafeEvaluator(ast.NodeVisitor):
#     def __init__(self, env):
#         self.env = env

#     def visit_Name(self, node):
#         if node.id == "env": return self.env
#         if node.id == "OPS": return OPS
#         if node.id in self.env: return self.env[node.id]
#         raise ValueError(f"æœªçŸ¥åç¨±: {node.id}")

#     def visit_Constant(self, node): return node.value

#     def visit_BinOp(self, node):
#         left, right = self.visit(node.left), self.visit(node.right)
#         if isinstance(node.op, ast.Add): return left + right
#         if isinstance(node.op, ast.Sub): return left - right
#         if isinstance(node.op, ast.Mult): return left * right
#         # if isinstance(node.op, ast.Div): return left / (right + 1e-12)
#         if isinstance(node.op, ast.Div):  return left / right   # â† ä¸è¦å·å· +1e-12
#         raise ValueError(f"Unsupported operator: {node.op}")

#     def visit_UnaryOp(self, node):
#         val = self.visit(node.operand)
#         return -val if isinstance(node.op, ast.USub) else val

#     def visit_Call(self, node):
#         func = self.visit(node.func)
#         args = [self.visit(a) for a in node.args]
#         return func(*args)

#     def visit_Attribute(self, node):
#         value = self.visit(node.value)
#         return getattr(value, node.attr)

#     def visit_Subscript(self, node):
#         value = self.visit(node.value)
#         key = self.visit(node.slice)
#         return value[key]

#     def visit_Compare(self, node):
#         left = self.visit(node.left)
#         right = self.visit(node.comparators[0])
#         op = node.ops[0]
#         if isinstance(op, ast.Gt):
#             return (left > right).astype(float)
#         elif isinstance(op, ast.Lt):
#             return (left < right).astype(float)
#         elif isinstance(op, ast.GtE):
#             return (left >= right).astype(float)
#         elif isinstance(op, ast.LtE):
#             return (left <= right).astype(float)
#         elif isinstance(op, ast.Eq):
#             return (left == right).astype(float)
#         elif isinstance(op, ast.NotEq):
#             return (left != right).astype(float)
#         else:
#             raise ValueError(f"Unsupported comparison operator: {op}")

# # =======================================================
# # 5ï¸âƒ£ ä¸»é©—è­‰æµç¨‹
# # =======================================================
# def verify_symbol(symbol: str, year: int = 1992,
#                   train_type: str = "train",
#                   data_dir="./data/day1",
#                   result_dir="./data/qlib_data/day1/generated_datasets/incremental_pretrain"):
#     raw = pd.read_csv(Path(data_dir) / f"{symbol}.csv")
#     raw["datetime"] = pd.to_datetime(raw["k_datetime"])
#     raw.set_index("datetime", inplace=True)
#     raw = raw[~raw.index.duplicated(keep="first")]
#     raw["volume"] = pd.to_numeric(raw["volume"], errors="coerce") 
#     raw["vwap"] = (raw["high"] + raw["low"] + raw["close"]) / 3

#     env = {c: raw[c] for c in ["open", "high", "low", "close", "volume", "vwap"]}
    
#     handler = Alpha158(instruments=[symbol], start_time="1980-01-01", end_time="2024-12-31")
#     feature_expressions, feature_names = handler.get_feature_config()

#     evaluator = SafeEvaluator(env)
#!     results = {}
#     for name, expr in zip(feature_names, feature_expressions):
#         try:
#             tree = ast.parse(qlib_expr_to_python(expr), mode="eval")
#             results[name] = evaluator.visit(tree.body)
#         except Exception as e:
#             results[name] = None
#!             print(f"{name} âŒ {e}")

#     # === è®€å– qlib è¼¸å‡ºçµæžœ ===
#     result_path = Path(result_dir) / f"{train_type}/{year}.csv"    
#     qlib_result = pd.read_csv(result_path)
#     qlib_result["symbol"] = qlib_result["symbol"].astype(str).str.strip()
#     qlib_result["date"] = pd.to_datetime(qlib_result["date"])
#     qlib_result.set_index("date", inplace=True)
#     qlib_result = qlib_result[qlib_result["symbol"] == symbol].copy()
#     print(qlib_result.head())
    
#     out = []
#     compare_all = []  # ðŸ§© æ”¶é›†æ‰€æœ‰ç‰¹å¾µå°ç…§è¡¨


#     for name in feature_names:
#         if results[name] is None or name not in qlib_result.columns:
#             out.append((name, None))
#             continue

        
#         # === ç§»é™¤é‡è¤‡æ—¥æœŸ ===
#         s1 = results[name].loc[~results[name].index.duplicated(keep="first")]
#         s2 = qlib_result[name].loc[~qlib_result.index.duplicated(keep="first")]

#         # === å°é½Šæ—¥æœŸ ===
#         s1, s2 = s1.align(s2, join="inner")

#         if len(s1) == 0:
#             out.append((name, None))
#             continue

#         mae = np.nanmean(np.abs(s1 - s2))
#         out.append((name, mae))

#         # === ðŸ§© æ”¶é›†å®Œæ•´å°ç…§çµæžœ ===
#         compare_df = pd.DataFrame({
#             "feature": name,
#             "date": s1.index,
#             "our_calc": s1.values,
#             "qlib_calc": s2.values,
#             "diff": (s1 - s2).values
#         })
#         compare_all.append(compare_df)

#     # === çµ±è¨ˆçµæžœ ===
#     out_df = pd.DataFrame(out, columns=["feature", "MAE"])
#     out_path = Path(f"./verify_result_{symbol}.csv")
#     out_df.to_csv(out_path, index=False)
#     print(f"\nâœ… æŒ‡æ¨™èª¤å·®çµ±è¨ˆè¼¸å‡ºï¼š{out_path}")

#     # === åˆä½µæ‰€æœ‰å°ç…§ ===
#     compare_all_df = pd.concat(compare_all, ignore_index=True)
#     compare_out_path = Path(f"./verify_result_compare_{symbol}.csv")
#     compare_all_df.to_csv(compare_out_path, index=False)
#     print(f"âœ… å®Œæ•´å°ç…§è¼¸å‡ºï¼š{compare_out_path}")


#     # === Step X: æ‰¾å‡ºèª¤å·®å¤§çš„ç‰¹å¾µé€²è¡Œ Debug ===
#     threshold = 1e-3  # ðŸ”§ èª¤å·®é–€æª»ï¼Œå¯èª¿æ•´
#     print(f"\n=== ðŸ” å·®ç•°è¶…éŽ {threshold} çš„ç‰¹å¾µ Debug ===")

#     # è¼‰å…¥çµæžœ
#     out_df = pd.read_csv(f"./verify_result_{symbol}.csv")
#     diff_features = out_df[out_df["MAE"].fillna(0) > threshold]["feature"].tolist()

#     # # ç”¨ç›¸å°èª¤å·®ï¼ˆæŽ¨è–¦ï¼‰
#     # out_df["relative_err"] = out_df["MAE"] / (out_df["MAE"].abs().mean() + 1e-12)
#     # diff_features = out_df[out_df["relative_err"] > 1e-6]["feature"].tolist()
    

#     if not diff_features:
#         print("âœ… æ‰€æœ‰ç‰¹å¾µèª¤å·®çš†åœ¨æ­£å¸¸ç¯„åœå…§")
#     else:
#         print(f"âš ï¸ å…± {len(diff_features)} å€‹ç‰¹å¾µè¶…éŽé–¾å€¼ï¼š{diff_features}")

#         compare_all_df = pd.read_csv(f"./verify_result_compare_{symbol}.csv")

#         # é‡æ–°è¼‰å…¥ feature config
#         handler = Alpha158(instruments=[symbol], start_time="2010-01-01", end_time="2024-12-31")
#         feature_expressions, feature_names = handler.get_feature_config()
#         expr_map = dict(zip(feature_names, feature_expressions))

#         for name in diff_features:
#             expr = expr_map.get(name)
#             if expr is None:
#                 print(f"\n=== Debug {name} ===\nâš ï¸ æ‰¾ä¸åˆ°å…¬å¼")
#                 continue

#             print(f"\n=== Debug {name} ===")
#             print("åŽŸå§‹å…¬å¼:", expr)

#             try:
#                 py_expr = qlib_expr_to_python(expr)
#                 print("è½‰æ›å¾Œå…¬å¼:", py_expr)

#                 tree = ast.parse(py_expr, mode="eval")
#                 our_calc = SafeEvaluator(env).visit(tree.body)

#                 # å–å‡º qlib è¨ˆç®—å€¼
#                 sub = compare_all_df[compare_all_df["feature"] == name].copy()
#                 sub["abs_diff"] = sub["diff"].abs()
#                 sub_top = sub.sort_values("abs_diff", ascending=False).head(5)

#                 print(f"âœ… Qlib vs æˆ‘å€‘è¨ˆç®—å·®ç•° Top 5:")
#                 print(sub_top[["date", "our_calc", "qlib_calc", "diff"]])
#             except Exception as e:
#                 print(f"{name} âŒ éŒ¯èª¤:", e)


# # =======================================================
# # 6ï¸âƒ£ åŸ·è¡Œå…¥å£
# # =======================================================
# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--symbol", required=True, help="è‚¡ç¥¨ä»£è™Ÿï¼Œä¾‹å¦‚ 1101")
#     parser.add_argument("--train_type", default="train", help="train / valid")
#     args = parser.parse_args()
#     verify_symbol(args.symbol, train_type=args.train_type)

    

"""
âœ… qlib_verify_genrate_datasets.py
-------------------------------------------------------
é‡ç¾ Qlib Alpha158 æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™ä¸¦é©—è­‰çµæžœä¸€è‡´æ€§

æ”¯æ´æ¨¡å¼ï¼š
1ï¸âƒ£ incremental_pretrainï¼ˆæœƒåŒæ™‚é©—è­‰ train + validï¼‰
2ï¸âƒ£ online_ftï¼ˆé©—è­‰æŒ‡å®šæ—¥æœŸï¼‰

ä½¿ç”¨æ–¹å¼ï¼š
-------------------------------------------------------
Incremental Pretrain é©—è­‰ï¼š
python ./src/qlib_verify_genrate_datasets.py --symbol 1101 --mode incremental_pretrain --year 1992

Online Fine-tuning é©—è­‰ï¼š
python ./src/qlib_verify_genrate_datasets.py --symbol 1101 --mode online_ft --date 1993-01-05
-------------------------------------------------------
"""

import ast
import argparse
from pathlib import Path
import numpy as np
import pandas as pd
from qlib.contrib.data.handler import Alpha158
import qlib
import re

# =======================================================
# 1ï¸âƒ£ åˆå§‹åŒ– Qlib
# =======================================================
qlib.init(provider_uri="./data/qlib_data/day1", region="cn", num_workers=8)
print("âœ… Qlib Initialized")

# =======================================================
# 2ï¸âƒ£ é‹ç®—å‡½æ•¸è¡¨ï¼ˆOPSï¼‰
# =======================================================
OPS = {
    # ---------------------------------------------------
    # åŸºæœ¬é‹ç®—é¡žï¼ˆå–®è®Šæ•¸æ“ä½œï¼‰
    # ---------------------------------------------------
    "Greater": np.maximum,     # å–è¼ƒå¤§å€¼
    "Less": np.minimum,        # å–è¼ƒå°å€¼
    "Abs": np.abs,             # çµ•å°å€¼
    "Log": np.log,             # è‡ªç„¶å°æ•¸
    "SignedPower": lambda x, y: np.sign(x) * np.abs(x) ** y,  # ä¿ç•™ç¬¦è™Ÿçš„æ¬¡æ–¹

    # ---------------------------------------------------
    # æ»¾å‹•çµ±è¨ˆé¡žï¼ˆRolling Statisticsï¼‰
    # ---------------------------------------------------
    "Mean": lambda x, n: x.rolling(int(n), min_periods=1).mean(),  # æ»¾å‹•å¹³å‡
    "Std":  lambda x, n: x.rolling(int(n), min_periods=1).std(),   # æ»¾å‹•æ¨™æº–å·®
    "Var":  lambda x, n: x.rolling(int(n), min_periods=1).var(),   # æ»¾å‹•è®Šç•°æ•¸
    "Max":  lambda x, n: x.rolling(int(n), min_periods=1).max(),   # æ»¾å‹•æœ€å¤§å€¼
    "Min":  lambda x, n: x.rolling(int(n), min_periods=1).min(),   # æ»¾å‹•æœ€å°å€¼
    "Sum":  lambda x, n: x.rolling(int(n), min_periods=1).sum(),   # æ»¾å‹•åŠ ç¸½
    "Ref":  lambda x, n: x.shift(int(n)),                          # å¾€å‰ä½ç§»ï¼ˆRef/Delay ç­‰åƒ¹ï¼‰

    # ---------------------------------------------------
    # æŽ’åèˆ‡åˆ†ä½é¡žï¼ˆRanking & Quantileï¼‰
    # ---------------------------------------------------
    "Rank": lambda x, n=None: (  # å€é–“å…§ç™¾åˆ†æ¯”æŽ’å
        x.rolling(int(n), min_periods=1).apply(lambda s: s.rank(pct=True).iloc[-1])
        if n else x.rank(pct=True)
    ),
    "Quantile": lambda x, n, q: x.rolling(int(n), min_periods=1).quantile(float(q)),  # åˆ†ä½æ•¸

    # ---------------------------------------------------
    # ç·šæ€§å›žæ­¸é¡žï¼ˆRegression-based Featuresï¼‰
    # ---------------------------------------------------
    "Slope": lambda x, n: x.rolling(int(n), min_periods=3).apply(
        lambda s: np.polyfit(np.arange(len(s)), s, 1)[0] if len(s.dropna()) > 2 else np.nan
    ),  # å›žæ­¸æ–œçŽ‡
    "Rsquare": lambda x, n: x.rolling(int(n), min_periods=3).apply(
        lambda s: (np.corrcoef(np.arange(len(s)), s)[0, 1] ** 2)
        if s.std() > 0 else np.nan
    ),  # å›žæ­¸æ±ºå®šä¿‚æ•¸ (RÂ²)
    "Resi": lambda x, n: x.rolling(int(n), min_periods=3).apply(
        lambda s: s.iloc[-1] - np.poly1d(np.polyfit(np.arange(len(s)), s, 1))(len(s) - 1)
        if len(s.dropna()) > 2 else np.nan
    ),  # æ®˜å·®ï¼ˆå¯¦éš›å€¼ - ç·šæ€§å›žæ­¸é æ¸¬å€¼ï¼‰

    # ---------------------------------------------------
    # ä½ç½®èˆ‡ç´¢å¼•é¡žï¼ˆIndex / Positionï¼‰
    # ---------------------------------------------------
    "IdxMax": lambda x, n: x.rolling(int(n), min_periods=1).apply(lambda s: np.argmax(s) + 1, raw=True),  # æœ€å¤§å€¼ä½ç½®
    "IdxMin": lambda x, n: x.rolling(int(n), min_periods=1).apply(lambda s: np.argmin(s) + 1, raw=True),  # æœ€å°å€¼ä½ç½®

    # ---------------------------------------------------
    # é›™è®Šæ•¸çµ±è¨ˆé¡žï¼ˆPairwise Statisticsï¼‰
    # ---------------------------------------------------
    "Corr": lambda x, y, n: x.rolling(int(n), min_periods=3).corr(y),  # ç›¸é—œä¿‚æ•¸
}


# OPS = {
#     "Greater": np.maximum,
#     "Less": np.minimum,
#     "Abs": np.abs,
#     "Log": np.log,
#     "SignedPower": lambda x, y: np.sign(x) * np.abs(x) ** y,

#     "Mean": lambda x, n: x.rolling(int(n), min_periods=1).mean(),
#     "Std": lambda x, n: x.rolling(int(n), min_periods=1).std(),
#     "Var": lambda x, n: x.rolling(int(n), min_periods=1).var(),
#     "Max": lambda x, n: x.rolling(int(n), min_periods=1).max(),
#     "Min": lambda x, n: x.rolling(int(n), min_periods=1).min(),
#     "Sum": lambda x, n: x.rolling(int(n), min_periods=1).sum(),
#     "Delay": lambda x, n: x.shift(int(n)),
#     "Ref": lambda x, n: x.shift(int(n)),

#     "Rank": lambda x, n=None: (
#         x.rolling(int(n), min_periods=1).apply(lambda s: s.rank(pct=True).iloc[-1])
#         if n else x.rank(pct=True)
#     ),
#     "Quantile": lambda x, n, q: x.rolling(int(n), min_periods=1).quantile(float(q)),

#     "Slope": lambda x, n: x.rolling(int(n), min_periods=3).apply(
#         lambda s: np.polyfit(np.arange(len(s)), s, 1)[0] if len(s.dropna()) > 2 else np.nan
#     ),
#     "Rsquare": lambda x, n: x.rolling(int(n), min_periods=3).apply(
#         lambda s: (np.corrcoef(np.arange(len(s)), s)[0, 1] ** 2)
#         if s.std() > 0 else np.nan
#     ),
#     "Resi": lambda x, n: x.rolling(int(n), min_periods=3).apply(
#         lambda s: s.iloc[-1] - np.poly1d(np.polyfit(np.arange(len(s)), s, 1))(len(s) - 1)
#         if len(s.dropna()) > 2 else np.nan
#     ),
#     "Beta": lambda x, y, n: x.rolling(int(n), min_periods=1).cov(y)
#         / (y.rolling(int(n), min_periods=1).var() + 1e-12),

#     "IdxMax": lambda x, n: x.rolling(int(n), min_periods=1).apply(lambda s: np.argmax(s) + 1, raw=True),
#     "IdxMin": lambda x, n: x.rolling(int(n), min_periods=1).apply(lambda s: np.argmin(s) + 1, raw=True),
#     "IMXD": lambda x, n: OPS["IdxMax"](x, n) - OPS["IdxMin"](x, n),

#     "CNTP": lambda x, n: x.diff().fillna(0).gt(0).rolling(int(n), min_periods=1).sum(),
#     "CNTN": lambda x, n: x.diff().fillna(0).lt(0).rolling(int(n), min_periods=1).sum(),
#     "CNTD": lambda x, n: x.diff().fillna(0).eq(0).rolling(int(n), min_periods=1).sum(),

#     "VMA": lambda v, n: OPS["Mean"](v, n) / (v + 1e-12),
#     "VSTD": lambda v, n: OPS["Std"](v, n) / (v + 1e-12),

#     "Cov": lambda x, y, n: x.rolling(int(n), min_periods=3).cov(y),
#     "Corr": lambda x, y, n: x.rolling(int(n), min_periods=3).corr(y),
#     "CORD": lambda x, y, n: (
#         (x / OPS["Ref"](x, 1))
#         .rolling(int(n), min_periods=1)
#         .corr(np.log(y / OPS["Ref"](y, 1)) + 1)
#     ),
# }

# =======================================================
# ðŸ” OPS ä½¿ç”¨è¿½è¹¤
# =======================================================
OPS_USED = set()   # ç´€éŒ„å¯¦éš›è¢«å‘¼å«éŽçš„é‹ç®—å­åç¨±
OPS_DEFINED = set(OPS.keys())  # æ‰€æœ‰å·²å®šç¾©çš„é‹ç®—å­åç¨±

def report_ops_usage():
    unused = OPS_DEFINED - OPS_USED
    print("\n===============================")
    print("ðŸ“Š OPS ä½¿ç”¨çµ±è¨ˆ")
    print("===============================")
    print(f"âœ… å·²å®šç¾©é‹ç®—å­æ•¸é‡ï¼š{len(OPS_DEFINED)}")
    print(f"ðŸŸ¢ æœ‰è¢«ä½¿ç”¨ï¼š{len(OPS_USED)}")
    print(f"âšª æœªè¢«ä½¿ç”¨ï¼š{len(unused)}")
    print("\nðŸŸ¢ ä½¿ç”¨éŽçš„é‹ç®—å­ï¼š")
    print(", ".join(sorted(OPS_USED)))
    print("\nâšª æœªè¢«ä½¿ç”¨çš„é‹ç®—å­ï¼š")
    print(", ".join(sorted(unused)))
    print("===============================")

# =======================================================
# 3ï¸âƒ£ Qlib DSL â†’ Python è½‰æ›
# =======================================================
def qlib_expr_to_python(expr: str) -> str:
    expr = expr.strip()
    expr = re.sub(r"\$(\w+)", r'env["\1"]', expr)
    expr = re.sub(r"\b([A-Z][A-Za-z0-9_]*)\s*\(", r'OPS["\1"](', expr)
    return re.sub(r"\s+", " ", expr)

# =======================================================
# 4ï¸âƒ£ AST å®‰å…¨è§£æžå™¨
# =======================================================
class SafeEvaluator(ast.NodeVisitor):
    def __init__(self, env):
        self.env = env

    def visit_Name(self, node):
        if node.id == "env": return self.env
        if node.id == "OPS": return OPS
        if node.id in self.env: return self.env[node.id]
        raise ValueError(f"æœªçŸ¥åç¨±: {node.id}")

    def visit_Constant(self, node): 
        return node.value

    def visit_BinOp(self, node):
        left, right = self.visit(node.left), self.visit(node.right)
        if isinstance(node.op, ast.Add): return left + right
        if isinstance(node.op, ast.Sub): return left - right
        if isinstance(node.op, ast.Mult): return left * right
        if isinstance(node.op, ast.Div): return left / right
        raise ValueError(f"Unsupported operator: {node.op}")

    def visit_UnaryOp(self, node):
        val = self.visit(node.operand)
        return -val if isinstance(node.op, ast.USub) else val

    def visit_Call(self, node):
        func = self.visit(node.func)
        args = [self.visit(a) for a in node.args]

        # --- è¿½è¹¤æ˜¯å¦ç‚º OPS ä¸­çš„å‡½å¼ ---
        if isinstance(node.func, ast.Subscript) and isinstance(node.func.value, ast.Name):
            if node.func.value.id == "OPS":
                op_name = self.visit(node.func.slice)
                OPS_USED.add(op_name)  # âœ… ç´€éŒ„è¢«ä½¿ç”¨çš„é‹ç®—å­
        return func(*args)

    def visit_Attribute(self, node):
        value = self.visit(node.value)
        return getattr(value, node.attr)

    def visit_Subscript(self, node):
        value = self.visit(node.value)
        key = self.visit(node.slice)
        
        try:
            return value[key]
        except Exception:
            raise KeyError(f"âŒ å­—å…¸ä¸­æ‰¾ä¸åˆ°éµï¼š{key}ï¼ˆç‰©ä»¶: {type(value).__name__}ï¼‰")

    # def visit_Compare(self, node):
    #     left = self.visit(node.left)
    #     right = self.visit(node.comparators[0])
    #     op = node.ops[0]
    #     if isinstance(op, ast.Gt):
    #         return (left > right).astype(float)
    #     elif isinstance(op, ast.Lt):
    #         return (left < right).astype(float)
    #     elif isinstance(op, ast.GtE):
    #         return (left >= right).astype(float)
    #     elif isinstance(op, ast.LtE):
    #         return (left <= right).astype(float)
    #     elif isinstance(op, ast.Eq):
    #         return (left == right).astype(float)
    #     elif isinstance(op, ast.NotEq):
    #         return (left != right).astype(float)
    #     else:
    #         raise ValueError(f"Unsupported comparison operator: {op}") 
    #    

# =======================================================
# 5ï¸âƒ£ é©—è­‰ä¸»ç¨‹å¼
# =======================================================
def verify_symbol(symbol: str, 
                  mode: str, 
                  year: int = None,
                  date: str = None,
                  base_dir: str = "./data/day1",
                  dataset_dir: str = "./data/qlib_data/day1/generated_datasets"):
    """
    mode: incremental_pretrain / online_ft
    """

    target_files = []

    if mode == "incremental_pretrain":
        # é©—è­‰ train + valid
        target_files = [
            Path(f"{dataset_dir}/incremental_pretrain/train/{year}.csv"),
            Path(f"{dataset_dir}/incremental_pretrain/valid/{year}.csv"),
        ]
    elif mode == "online_ft":
        if not date:
            raise ValueError("âŒ online_ft æ¨¡å¼éœ€è¦ --date åƒæ•¸")
        target_files = [Path(f"{dataset_dir}/online_ft/{date[:4]}/{date}.csv")]
    else:
        raise ValueError("âŒ mode å¿…é ˆæ˜¯ incremental_pretrain æˆ– online_ft")

    raw_path = Path(base_dir) / f"{symbol}.csv"

    for file_path in target_files:
        if not file_path.exists():
            print(f"âš ï¸ è·³éŽï¼Œæª”æ¡ˆä¸å­˜åœ¨ï¼š{file_path}")
            continue
        print(f"\n=== ðŸ§© é©—è­‰æª”æ¡ˆï¼š{file_path} ===")
        verify_single_file(symbol, raw_path, file_path)

# =======================================================
# 6ï¸âƒ£ å–®ä¸€æª”æ¡ˆé©—è­‰å‡½æ•¸
# =======================================================
def verify_single_file(symbol: str, raw_path: Path, result_path: Path):
    if not raw_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°åŽŸå§‹è³‡æ–™æª”æ¡ˆï¼š{raw_path}")
        return

    # --- è®€å…¥åŽŸå§‹è‚¡ç¥¨è³‡æ–™ ---
    raw = pd.read_csv(raw_path)
    raw["datetime"] = pd.to_datetime(raw["k_datetime"])
    raw.set_index("datetime", inplace=True)
    raw = raw[~raw.index.duplicated(keep="first")]
    raw["volume"] = pd.to_numeric(raw["volume"], errors="coerce")
    raw["vwap"] = (raw["high"] + raw["low"] + raw["close"]) / 3
    env = {c: raw[c] for c in ["open", "high", "low", "close", "volume", "vwap"]}

    # --- è¼‰å…¥ Qlib çµæžœ ---
    qlib_result = pd.read_csv(result_path)
    qlib_result.columns = [c.strip() for c in qlib_result.columns]
    qlib_result["symbol"] = qlib_result["symbol"].astype(str).str.strip()
    qlib_result["date"] = pd.to_datetime(qlib_result["date"])
    qlib_result.set_index("date", inplace=True)
    qlib_result = qlib_result[qlib_result["symbol"] == str(symbol).strip()].copy()

    if qlib_result.empty:
        print(f"âš ï¸ ç„¡ symbol={symbol} çš„è³‡æ–™ã€‚")
        return

    handler = Alpha158(instruments=[symbol], start_time="1980-01-01", end_time="2025-12-31")
    feature_expressions, feature_names = handler.get_feature_config()

    evaluator = SafeEvaluator(env)
    out, compare_all = [], []
    for name, expr in zip(feature_names, feature_expressions):
        if expr is None:
            print(f"\n=== Debug {name} ===\nâš ï¸ æ‰¾ä¸åˆ°å…¬å¼")
            continue

        print(f"\n=== Debug {name} ===")
        print("åŽŸå§‹å…¬å¼:", expr)

        try:
            py_expr = qlib_expr_to_python(expr)
            print("è½‰æ›å¾Œå…¬å¼:", py_expr)

            tree = ast.parse(py_expr, mode="eval")
            ours = evaluator.visit(tree.body)
        except Exception as e:
            ours = None
            print(f"{name} âŒ éŒ¯èª¤:", e)

        if ours is None or name not in qlib_result.columns:
            out.append((name, None))
            continue

        s1, s2 = ours.align(qlib_result[name], join="inner")
        if len(s1) == 0:
            out.append((name, None))
            continue

        mae = np.nanmean(np.abs(s1 - s2))
        out.append((name, mae))
        compare_all.append(pd.DataFrame({
            "feature": name, 
            "date": s1.index,
            "our_calc": s1.values,
            "qlib_calc": s2.values,
            "diff": (s1 - s2).values
        }))

    out_df = pd.DataFrame(out, columns=["feature", "MAE"])
    out_path = Path(f"./verify_{result_path.parent.stem}_result_{symbol}_{result_path.stem}.csv")
    out_df.to_csv(out_path, index=False)
    print(f"âœ… æŒ‡æ¨™èª¤å·®çµ±è¨ˆè¼¸å‡ºï¼š{out_path}")

    if compare_all:
        compare_out_path = Path(f"./verify_{result_path.parent.stem}_result_compare_{symbol}_{result_path.stem}.csv")
        pd.concat(compare_all, ignore_index=True).to_csv(compare_out_path, index=False)
        print(f"âœ… å®Œæ•´å°ç…§è¼¸å‡ºï¼š{compare_out_path}")

# =======================================================
# 7ï¸âƒ£ åŸ·è¡Œå…¥å£
# =======================================================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--symbol", required=True)
    parser.add_argument("--mode", choices=["incremental_pretrain", "online_ft"], required=True)
    parser.add_argument("--year", type=int, help="incremental_pretrain å¹´ä»½")
    parser.add_argument("--date", type=str, help="online_ft æ—¥æœŸ (YYYY-MM-DD)")
    args = parser.parse_args()

    verify_symbol(args.symbol, mode=args.mode, year=args.year, date=args.date)
    report_ops_usage()
