# =====================================================
# ğŸ”§ å¯èª¿åƒæ•¸ / è·¯å¾‘è¨­å®šï¼ˆå…¨éƒ¨é›†ä¸­åœ¨æœ€ä¸Šæ–¹ï¼‰
# =====================================================

MERGED_FEATURES_PATH = "./data/qlib_data/day1/generated_datasets/merged_features.parquet"

LOOKBACK = 60               # éå» N å¤©
BATCH_SIZE = 64
NUM_WORKERS = 4


META_COLS = ["symbol", "date", "year", "phase"]
OHLCV_COLS = ["open", "high", "low", "close", "volume"]
NON_FEATURE_COLS = ["VWAP0", "label"]

EXCLUDE_COLS = set(META_COLS + OHLCV_COLS + NON_FEATURE_COLS)

# =====================================================
#  ğŸš€ ä¸‹é¢é–‹å§‹ç‚º Dataset / Loader ä¸»é‚è¼¯
# =====================================================

import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader


# # =====================================================
# # ğŸ” æ ¹æ“š merged_features è‡ªå‹•æ¨ç®— train/valid/test å¹´åº¦ç•Œç·š
# # =====================================================
# def infer_date_boundaries(df: pd.DataFrame):
#     """
#     å¾ df çš„ phase=test è‡ªå‹•æ¨ç®—:
#     - train_end
#     - valid_end
#     - test_end
#     - train_year / valid_year / test_yearï¼ˆå¦‚éœ€æ›´é€²éšç”¨é€”ï¼‰
#     """

#     test_year = df[df["phase"] == "test"]["date"].max().year
#     valid_year = df[df["phase"] == "valid"]["date"].max().year
#     train_year = df[df["phase"] == "train"]["date"].max().year  
    
#     print(f"Train year: {train_year}, Valid year: {valid_year}, Test year: {test_year}")   
#     return (
#         f"{train_year}-12-31",
#         f"{valid_year}-12-31",
#         f"{test_year}-12-31",
#         train_year,
#         valid_year,
#         test_year
#     )

# =====================================================
# ğŸ§© è‡ªè¨‚ collate_fnï¼šé¿å… dates è¢« PyTorch äº‚ transpose
# =====================================================
def seq_collate_fn(batch):
    return {
        "symbol":   [b["symbol"] for b in batch],          # list[str], B
        "dates":    [b["dates"]  for b in batch],          # list[list[str]], BÃ—L
        "date":     [b["date"]   for b in batch],          # list[str], B  â† â˜… æ–°å¢
        "features": torch.stack([b["features"] for b in batch]),  # [B, L, F]
        "label":    torch.stack([b["label"]   for b in batch]),   # [B, 1]
    }

# =====================================================
# ğŸ§± LazySeqDatasetï¼šè·¨å¹´åº¦ window + æ¨™æº–åŒ– sample å»ºç«‹é‚è¼¯
# =====================================================
class LazySeqDataset(Dataset):
    """
    - subset ç”¨æ—¥æœŸåˆ‡ï¼ˆé¿å…çœ‹åˆ°æœªä¾†è³‡æ–™ï¼‰
    - sample æ‰€å±¬éšæ®µç”± label çš„ phase æ±ºå®šï¼ˆé¿å…æ´©æ¼ï¼‰
    - window è‡ªå‹•ç”± lookback æ§åˆ¶ï¼Œä¸æœƒæŠ“éé è³‡æ–™
    """

    def __init__(self, df, feature_cols, lookback, phase):
        self.df = df.sort_values(["symbol", "date"])
        self.feature_cols = feature_cols
        self.lookback = lookback
        self.phase = phase
        self.samples = []
        self._build_samples()

    def _build_samples(self):
        """æ»‘å‹• window å»ºç«‹ sample"""
        for symbol, g in self.df.groupby("symbol"):
            g = g.reset_index(drop=True)

            for end in range(self.lookback - 1, len(g)):
                start = end - self.lookback + 1

                # label æ‰€å±¬ phase â†’ æ±ºå®š sample å±¬æ–¼ train / valid / test
                if g.iloc[end]["phase"] != self.phase:
                    continue

                self.samples.append((symbol, g, start, end))

    def __len__(self):
        return len(self.samples)
        
    def __getitem__(self, idx):
        symbol, g, start, end = self.samples[idx]

        window = g.iloc[start: end + 1]
        assert len(window) == self.lookback

        features = window[self.feature_cols].to_numpy(dtype="float32")
        label = window.iloc[-1]["label"]
        label_date = window.iloc[-1]["date"]

        dates = window["date"].astype(str).tolist()

        return {
            "symbol": symbol,                
            "dates": dates,                               
            "features": torch.tensor(features),
            "date": str(label_date),
            "label": torch.tensor([label], dtype=torch.float32),
        }

# =====================================================
# ğŸ§© å»ºç«‹ train / valid / test Dataset + DataLoader
# =====================================================
def build_phase_dataset(df, phase_name, feature_cols,
                        lookback, batch_size, num_workers):
    ds = LazySeqDataset(df, feature_cols, lookback, phase_name)

    if len(ds) == 0:
        print(f"âš  Phase '{phase_name}' ç„¡è³‡æ–™")
        return None, None
    
    loader = DataLoader(
        ds,
        batch_size=batch_size,
        shuffle=(phase_name == "train"),
        num_workers=num_workers,
        drop_last=False,
        collate_fn=seq_collate_fn,
    )

    return ds, loader


# =====================================================
# ğŸ¯ ä¸»å…¥å£ï¼šä¾› train.py / eval.py å‘¼å«
# =====================================================
def prepare_datasets(
    merged_path=MERGED_FEATURES_PATH,
    lookback=LOOKBACK,
    batch_size=BATCH_SIZE,
    num_workers=NUM_WORKERS
):
    print("æº–å‚™è³‡æ–™ä¸­â€¦")

    df = pd.read_parquet(merged_path)
    df = df.sort_values(["symbol", "date"])
    print(df["symbol"].unique().shape[0], "æ”¯è‚¡ç¥¨")
    
    # ğŸ”¥ éæ¿¾è³‡æ–™å¤ªå°‘çš„è‚¡ç¥¨
    df = df.groupby("symbol").filter(lambda x: len(x) >= lookback)
    symbols = sorted(df["symbol"].unique().tolist())
    dates = sorted(df["date"].unique().tolist())
    print("éæ¿¾å¾Œå‰©ä¸‹", len(symbols), "æ”¯è‚¡ç¥¨")

    # ----------- ğŸ”¥ è‡ªå‹•å»ºç«‹ labelï¼ˆå¿…è¦ï¼‰ -----------
    df["label"] = df.groupby("symbol")["close"].shift(-1) / df["close"] - 1

    # ----------- ğŸ”¥ è™•ç†ç¼ºå€¼ï¼ˆå¿…è¦ï¼‰ -----------
    df = df.fillna(0)

    # ---- è‡ªå‹•æŠ“ feature columns ----
    feature_cols = [
        c for c in df.columns
        if c not in EXCLUDE_COLS
    ]
    print(f"Detected {len(feature_cols)} feature columns.")
    print(f"Feature columns: {feature_cols}")
    
    train_ds, train_loader = build_phase_dataset(
        df, "train", feature_cols, lookback, batch_size, num_workers
    )

    valid_ds, valid_loader = build_phase_dataset(
        df, "valid", feature_cols, lookback, batch_size, num_workers
    )

    test_ds, test_loader = build_phase_dataset(
        df, "test", feature_cols, lookback, batch_size, num_workers
    )

    print("Train samples:", len(train_ds))
    print("Valid samples:", len(valid_ds))
    print("Test samples :", len(test_ds))

    return (
        train_ds, train_loader,
        valid_ds, valid_loader,
        test_ds, test_loader,
        symbols, dates
    )


# =====================================================
# ğŸ§ª å·¥å…·ï¼šæª¢æŸ¥ Dataset ä¸­ä»»æ„ä¸€ç­† sample
# =====================================================
def get_last_sample_of_symbol(ds, symbol):
    """
    å›å‚³ Dataset ä¸­æŸæ”¯è‚¡ç¥¨æœ€å¾Œä¸€ç­† sample çš„ index
    ä¸¦å›å‚³è©² sample å…§å®¹
    """
    # æ‰¾å‡ºæ‰€æœ‰ sample çš„ index
    matched = []
    for i in range(len(ds)):
        if ds.samples[i][0] == symbol:
            matched.append(i)

    if len(matched) == 0:
        print(f"âŒ Symbol {symbol} not found in this dataset.")
        return None

    # æœ€å¾Œä¸€ç­† sample çš„ index = æœ€å¤§çš„ sample index
    last_idx = matched[-1]

    print(f"âœ” Symbol {symbol} æœ€å¾Œä¸€ç­† sample index = {last_idx}")
    return last_idx, ds[last_idx]

def inspect_sample(ds, index=0, n_show_rows=20):
    if ds is None or len(ds) == 0:
        print("âŒ Dataset is empty.")
        return

    sample = ds[index]
    print("Sample: ", sample)

    symbol = sample["symbol"]
    t_date = sample["date"]
    window_dates = sample["dates"]
    features = sample["features"].numpy()
    label = float(sample["label"].numpy())

    # æ‰¾åˆ°å®Œæ•´åºåˆ—
    g = ds.df[ds.df["symbol"] == symbol].sort_values("date").reset_index(drop=True)

    # æ‰¾åˆ° label row index
    idx = g.index[g["date"] == t_date][0]

    start_idx = idx - (ds.lookback - 1)
    end_idx = idx
    window_df = g.iloc[start_idx:end_idx + 1]

    print("\n================= SAMPLE DETAIL (LOOKBACK =", ds.lookback, ") =================\n")

    print(f"â–¶ Sample index     : {index}")
    print(f"â–¶ Symbol           : {symbol}")
    print(f"â–¶ Label date (t)   : {t_date}")
    print(f"â–¶ Window dates     : {window_dates}")
    print(f"â–¶ Label(tâ†’t+1 rtn) : {label:.6f}")
    print(f"â–¶ Label phase      : {g.loc[idx, 'phase']}")

    print("\nâ–¶ Window size      :", len(window_df))
    print("\n--- Window DataFrame with date, OHLCV and label ---")
    print(window_df[META_COLS + OHLCV_COLS + ["label"]])    
    print(f"â–¶ Window date range: {window_df['date'].iloc[0]} â†’ {window_df['date'].iloc[-1]}")

    # æ´©æ¼æª¢æŸ¥
    leakage = (window_df["date"] > t_date).any()
    print(f"â–¶ æœªä¾†è³‡æ–™æ´©æ¼ï¼Ÿ   : {'âŒYES' if leakage else 'âœ”NO'}")

    print("\n--- Time Line ---")
    print(f"[window] {window_df['date'].iloc[0]} â†’ ... â†’ {window_df['date'].iloc[-1]} â†’ [label] {t_date} â†’ t+1")

    print("\n--- Feature matrix shape ---")
    print(f"{features.shape}   (æ‡‰ç‚º {ds.lookback} x {len(ds.feature_cols)})")

    print("\n====================================================================\n")

# =====================================================
# ğŸ§ª å·¥å…·ï¼šæª¢æŸ¥ dataset ä¸­æ‰€æœ‰ window æ˜¯å¦å®Œæ•´
# =====================================================
def check_all_windows(ds):
    """
    å…¨é›† window å¥åº·æª¢æŸ¥ï¼š
    - ç¢ºèª window size æ˜¯å¦å®Œæ•´
    - æ‰¾å‡ºæ‰€æœ‰å¯èƒ½æ´©æ¼æœªä¾†è³‡æ–™çš„ sample
    - æ‰¾å‡ºè·¨ phase windowï¼ˆåˆæ³•ï¼Œä½†æä¾›å‘Šè­¦ï¼‰
    """

    print("\n==================== WINDOW CONSISTENCY CHECK ====================")

    problems = []
    leakage_cnt = 0
    cross_phase_cnt = 0

    total = len(ds)
    L = ds.lookback

    for i in range(total):
        symbol, g, start, end = ds.samples[i]

        # label row
        t_date = g.iloc[end]["date"]
        t_phase = g.iloc[end]["phase"]

        # window rows
        w = g.iloc[start:end+1]
        window_size = len(w)

        # 1. æª¢æŸ¥ window é•·åº¦
        if window_size != L:
            problems.append((i, symbol, t_date, window_size))
            continue

        # 2. æœªä¾†æ´©æ¼æª¢æŸ¥
        if (w["date"] > t_date).any():
            leakage_cnt += 1

        # 3. è·¨ phase æª¢æŸ¥ï¼ˆåˆæ³•ï¼Œä½†é¡¯ç¤ºçµ±è¨ˆï¼‰
        #   window èˆŠè³‡æ–™ phase å¯ä»¥æ˜¯ trainï¼Œlabel phase æ˜¯ valid/test â†’ åˆæ³•
        #   å¦‚æœ window ä¸­æœ‰æ¯” label phase æ›´ã€Œæœªä¾†ã€çš„è³‡æ–™ â†’ é•æ³•ï¼ˆç¬¬ 2 æ­¥å·²æ“‹ï¼‰
        phases_in_window = set(w["phase"].unique())
        if t_phase not in phases_in_window:
            cross_phase_cnt += 1

    print(f"âœ” Dataset: {total} samples")
    print(f"âœ” Lookback: {L}")
    
    if problems:
        print("\nâŒ Window ç¼ºè³‡æ–™æ¨£æœ¬:")
        for (idx, sym, date, ws) in problems[:20]:
            print(f"  - Sample {idx} | {sym} @ {date} | window rows = {ws} (should be {L})")
        print(f"... å…± {len(problems)} ç­†ä¸å®Œæ•´ window")
    else:
        print("âœ” æ‰€æœ‰ window éƒ½æœ‰å®Œæ•´é•·åº¦")

    if leakage_cnt > 0:
        print(f"\nâŒ æœªä¾†è³‡æ–™æ´©æ¼: å…± {leakage_cnt} ç­†ï¼ˆåš´é‡ï¼‰")
    else:
        print("âœ” ç„¡æœªä¾†è³‡æ–™æ´©æ¼")

    print(f"\nâš  è·¨ phase windowï¼ˆæ­£å¸¸ç¾è±¡ï¼Œç”¨æ–¼æ™‚é–“åºåˆ—ï¼‰: {cross_phase_cnt} ç­†")
    print("   ï¼ˆä¾‹å¦‚ valid sample éœ€è¦ 1991 çš„ train è³‡æ–™ â†’ åˆæ³•ï¼‰")

    print("\n==================================================================\n")


# =====================================================
# âœ” æ¸¬è©¦åŸ·è¡Œï¼ˆä½ å¯ç§»é™¤ï¼‰
# =====================================================
if __name__ == "__main__":
    train_ds, train_loader, valid_ds, valid_loader, test_ds, test_loader, symbols, dates = prepare_datasets()


    # çœ‹ train sample
    idx, _ = get_last_sample_of_symbol(train_ds, "1101")
    inspect_sample(train_ds, 0)
    inspect_sample(train_ds, idx)


    # çœ‹ valid sample
    idx, _ = get_last_sample_of_symbol(valid_ds, "1101")
    inspect_sample(valid_ds, 0)
    inspect_sample(valid_ds, idx)

    # çœ‹ test sample
    idx, _ = get_last_sample_of_symbol(test_ds, "1101")
    inspect_sample(test_ds, 0)
    inspect_sample(test_ds, idx)

    check_all_windows(train_ds)
    check_all_windows(valid_ds)
    check_all_windows(test_ds)