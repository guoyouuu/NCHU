"""
===============================================================
ğŸ“˜ è‚¡ç¥¨æ­·å²è³‡æ–™å®Œæ•´æ€§æª¢æŸ¥å·¥å…· (v2 Clean Edition)
---------------------------------------------------------------
ç”¨é€”ï¼š
    - æª¢æŸ¥å¤šæª”è‚¡ç¥¨æ­·å²è³‡æ–™ï¼ˆæ¯æª”ä¸€å€‹ CSVï¼‰
    - ä»¥åŠ æ¬ŠæŒ‡æ•¸æˆ–å¸‚å ´æ—¥æ›† (weight.csv) ç‚ºåŸºæº–
    - ç¢ºèªæ¯æ”¯è‚¡ç¥¨çš„æ—¥æœŸå°é½Šã€ç¼ºå€¼ã€åœç‰Œå¤©æ•¸ã€é›¶é‡æ¯”ä¾‹ç­‰
    - è‡ªå‹•ç”Ÿæˆå ±å‘Š data_check_summary.csv

ç‰¹é»ï¼š
    âœ… ä»¥è‚¡ç¥¨æ›ç‰ŒæœŸé–“ (IPO window) ç‚ºåŸºæº–è¨ˆç®—ç¼ºå€¼èˆ‡åœç‰Œ
    âœ… å°‡å…¨å¸‚å ´åŸºæº– (full window) æŒ‡æ¨™ä¿ç•™ä½œåƒè€ƒ
    âœ… åƒ…ä½¿ç”¨å¯¦éš›æª”æ¡ˆå…§ volume è¨ˆç®—åœç‰Œæ¯”ä¾‹
    âœ… æ˜ç¢ºå€åˆ†éŒ¯èª¤ã€è­¦ç¤ºã€èˆ‡æ­£å¸¸è‚¡ç¥¨

ä½¿ç”¨æ–¹å¼ï¼š
    python check_with_calendar_v2_clean.py

æª”æ¡ˆéœ€æ±‚ï¼š
    1. weigt.csv (å«æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œæ¬„ä½ k_datetime)
    2. data/day1/*.csv (å€‹è‚¡æ­·å²æª”ï¼Œæ¬„ä½è‡³å°‘å« k_datetime, open, high, low, close, volume)

è¼¸å‡ºï¼š
    data_check_summary.csv


===============================================================
"""

import os
import pandas as pd
from tqdm import tqdm

# ---------------------------------------------------------------
# ğŸ§© åƒæ•¸è¨­å®š
# ---------------------------------------------------------------
CALENDAR_CSV = "data/day1/weigt.csv"        # å«æ‰€æœ‰äº¤æ˜“æ—¥ (k_datetime)
STOCK_DIR = "data/day1"            # å€‹è‚¡è³‡æ–™ç›®éŒ„
SUMMARY_OUT = "data/day1/summary_data.csv"

# è­¦ç¤ºé–¾å€¼è¨­å®š
LONG_GAP_WARN_DAYS = 7             # é€£çºŒç¼ºæ—¥è¶…é 7 å¤©è­¦å‘Š
LONG_GAP_EXCL_DAYS = 30            # è¶…é 30 å¤©é€šå¸¸å‰”é™¤
ZERO_VOL_WARN_RATIO = 0.5          # volume=0 æ¯”ä¾‹è¶…é 50% è­¦å‘Š
ZERO_VOL_STREAK_WARN = 10          # é€£çºŒ volume=0 è¶…é 10 å¤©è­¦å‘Š


# ---------------------------------------------------------------
# ğŸ§  å·¥å…·å‡½å¼
# ---------------------------------------------------------------

def longest_streak(bool_series: pd.Series) -> int:
    """è¨ˆç®—å¸ƒæ—åºåˆ—ä¸­ True çš„æœ€é•·é€£çºŒé•·åº¦ã€‚"""
    max_len = 0
    count = 0
    for value in bool_series:
        if value:
            count += 1
            max_len = max(max_len, count)
        else:
            count = 0
    return max_len


# ---------------------------------------------------------------
# âš™ï¸ ä¸»ç¨‹å¼
# ---------------------------------------------------------------
def run():
    # === 1ï¸âƒ£ è®€å–å¸‚å ´äº¤æ˜“æ—¥æ›† ===
    cal = pd.read_csv(CALENDAR_CSV, parse_dates=["k_datetime"])
    cal = cal.sort_values("k_datetime")[["k_datetime"]].drop_duplicates().reset_index(drop=True)
    cal_dates = cal["k_datetime"]

    results = []
    stock_files = [f for f in os.listdir(STOCK_DIR) if f.endswith(".csv")]

    # === 2ï¸âƒ£ é€æª”æª¢æŸ¥å€‹è‚¡è³‡æ–™ ===
    for fname in tqdm(stock_files):
        path = os.path.join(STOCK_DIR, fname)
        result = {"file": fname}

        try:
            df = pd.read_csv(path, parse_dates=["k_datetime"])
        except Exception as e:
            result.update({"error": f"read_error:{e}"})
            results.append(result)
            continue

        # æª¢æŸ¥å¿…è¦æ¬„ä½
        required_cols = {"k_datetime", "open", "high", "low", "close", "volume"}
        if not required_cols.issubset(df.columns):
            result.update({"error": "missing_columns"})
            results.append(result)
            continue

        # æ’åºæ—¥æœŸèˆ‡å»é‡
        df = df.sort_values("k_datetime").drop_duplicates(subset=["k_datetime"]).reset_index(drop=True)
        if df.empty:
            result.update({"error": "empty_file"})
            results.append(result)
            continue

        # === åŸºæœ¬è³‡è¨Š ===
        start_date = df["k_datetime"].iloc[0]
        end_date = df["k_datetime"].iloc[-1]
        result.update({
            "start_date": str(start_date.date()),
            "end_date": str(end_date.date()),
            "row_count": len(df)
        })

        # === 3ï¸âƒ£ æ˜¯å¦æœ‰éäº¤æ˜“æ—¥ç´€éŒ„ ===
        has_non_trading = (~df["k_datetime"].isin(cal_dates)).any()
        result["has_non_trading_dates"] = int(has_non_trading)

        # === 4ï¸âƒ£ å…¨å¸‚å ´æ—¥æ›†åŸºæº– (full window) ===
        merged_full = cal.merge(df, on="k_datetime", how="left", sort=True)
        is_missing_full = merged_full[["open", "high", "low", "close", "volume"]].isna().all(axis=1)
        result["missing_days_full"] = int(is_missing_full.sum())
        result["missing_ratio_full"] = round(float(is_missing_full.mean()), 6)
        result["longest_missing_streak_full"] = longest_streak(is_missing_full)

        # === 5ï¸âƒ£ æ›ç‰ŒæœŸé–“åŸºæº– (IPO window) ===
        cal_ipo = cal[(cal["k_datetime"] >= start_date) & (cal["k_datetime"] <= end_date)]
        merged_ipo = cal_ipo.merge(df, on="k_datetime", how="left", sort=True)
        is_missing_ipo = merged_ipo[["open", "high", "low", "close", "volume"]].isna().all(axis=1)

        result["missing_days_ipo"] = int(is_missing_ipo.sum())
        result["missing_ratio_ipo"] = round(float(is_missing_ipo.mean()), 6)
        result["longest_missing_streak_ipo"] = longest_streak(is_missing_ipo)

        # === 6ï¸âƒ£ æª”æ¡ˆå…§æ—¥æœŸé–“éš” ===
        if len(df) >= 2:
            result["max_gap_by_diff"] = int(df["k_datetime"].diff().dt.days.dropna().max())
        else:
            result["max_gap_by_diff"] = 0

        # === 7ï¸âƒ£ æª”æ¡ˆå…§é›¶é‡çµ±è¨ˆ ===
        zero_vol = df["volume"].fillna(0).eq(0)
        result["zero_vol"] = zero_vol.sum()
        result["zero_volume_ratio_file"] = round(float(zero_vol.mean()), 6)
        result["longest_zero_vol_streak_file"] = longest_streak(zero_vol)

        # === 8ï¸âƒ£ è­¦ç¤ºæ——æ¨™ ===
        warn_flags = []
        if has_non_trading:
            warn_flags.append("has_non_trading_dates")
        if result["longest_missing_streak_ipo"] >= LONG_GAP_WARN_DAYS:
            warn_flags.append(f"gap_ipo>={LONG_GAP_WARN_DAYS}")
        if result["longest_missing_streak_ipo"] >= LONG_GAP_EXCL_DAYS:
            warn_flags.append(f"gap_ipo>={LONG_GAP_EXCL_DAYS}")
        if result["zero_volume_ratio_file"] > ZERO_VOL_WARN_RATIO:
            warn_flags.append(f"zero_vol>={ZERO_VOL_WARN_RATIO*100:.0f}%")
        if result["longest_zero_vol_streak_file"] >= ZERO_VOL_STREAK_WARN:
            warn_flags.append(f"zero_vol_streak>={ZERO_VOL_STREAK_WARN}")

        result["warn_flag"] = "|".join(warn_flags) if warn_flags else ""
        result["error"] = ""  # æˆåŠŸ

        results.append(result)

    # === 9ï¸âƒ£ è¼¸å‡ºå ±å‘Š ===
    report = pd.DataFrame(results)
    report.to_csv(SUMMARY_OUT, index=False)
    print(f"âœ… å®Œæˆï¼å…± {len(report)} æª”è‚¡ç¥¨ï¼Œå ±å‘Šè¼¸å‡ºè‡³ï¼š{SUMMARY_OUT}")


# ---------------------------------------------------------------
# ğŸš€ åŸ·è¡Œ
# ---------------------------------------------------------------
if __name__ == "__main__":
    run()
